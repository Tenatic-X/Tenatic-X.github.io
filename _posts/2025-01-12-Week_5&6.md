---
layout: post
title: "Week 5&6"
description: "Week 5&6"
tags: Weekly(ish)_update
todolist: Title, Overview, Projects and Tasks, Challenges and Solutions, Learnings and Insights, Next Steps, Reflections
---

# Week 5 & 6

## Relevant Project
[00_tensorflow_2_quickstart](https://tenatic-x.github.io/projects/00_tensorflow_2_quickstart.html)

[01_neural_network_regression_with_tensorflow](https://tenatic-x.github.io/projects/01_neural_network_regression_with_tensorflow.html)

## Overview
I've been continuing on chipping away on TensorFlow ZtM online course for the past 2 weeks. This time, working on the second notebook where we're mostly learning on the basics/barebones on how machine learning and neural networks work on a made up dataset.

## Project and Tasks
* Complete 00's extra-cirricular contents: *Using Keras to create a very barebones image classifying ML model.*
* Finish ZTM Notebook 01: *Finish going through and retyping the first notebook on `Visual Code Studio`, and use ChatGPT to help explain processes I was unfamiliar with.*

## Challenges and Learnings

### What's the neural network/machine learning model's pipeline?
It comes down to a few basic but expanadable steps: 
* Getting your data
* Clean/Setup your data to make it ready for a ML model to train on
* Create a ML model, and start implementing/experimenting with it to get the best results
* Evaluate and visualize the output of the results

Fortunately, workbook 01's contents was quite familiar to me. 6 months ago, I've done a Microsoft Accelerator program from my local Uni (Uni of Aucks) that taught Data Science online, and have passed their phase 2, where we were required to build a ML model identifying 10 breeds of dogs from kaggle. So it's been a great refresher for me.

### `Input` and `Output` shapes
At first I was a little confused about Input and Output shapes. But it's just stating the number of variables you plan to have the model injest firstly, and what variables should be excreted at the end of the pipeline. Say I give it 5 different variables that state the dimension of a shape, and it's gonna have to poop out 1 variable, stating what shape it thinks best fit those dimensions. Here's an image for representation/explanatory purposes

![01-input-and-output-shapes-housing-prices](https://github.com/user-attachments/assets/2b0699fe-527e-4279-92dc-bf99754ef533)

### `tf.expand_dims()`
One fucking annoying thing about the `Input`, `Output` thing, is this specific code `tf.expand_dims()` for TensorFlow 2.7.0 and above. So what does it do? Its to expand the dimensions of any specific data you want, but why is that needed? This is because of the input shape that your model expects in its input. It wants a 2D array, rather than a 1D. When we fit the model on the training data using `model.fit()`, it would automatically apply this dimensions expansion for you. But future TensorFlow updates won't allow this. It really breaks the flow of finally implementing all your model's layers, functions, and metrics, then you have to type :
```python
model.fit(tf.expand_dims(X, axis=-1), y, epochs-100)
```
Rather than doing the more efficient and simpler method of:
```python
model.fit(X, y, epochs=100)
```
So much easier on the eyes!


### Improving the model, and Sequential layers
There are many ways one can choose to improve the accuracy of the model, once they got their first modular results. The one that's often more complex, is the model's layers.

So far, I've learnt the sequential layering method, in creating a neural network/ML model, `tf.keras.Sequential([])` where the code is read from top to bottom, and is stacked like a layer of pancakes. This is the main body of the model. You can also choose to change and modify through the compiling of models in their `optimizer` function, as they play a role in the model's performance.

For `tf.keras.Sequential([])`, I've had a go using `Dense` layers, which can be simply put as the neural network's nodes. Where the ML model makes tweaks on the nodes to better fit it on the training data it has given. These tweaks are supposed to make the model better at finding the results you as the data scientist/ML engineer wants.

Here's another illustration on the limitless ways one can improve on a ML model's predictions.
<img width="890" alt="02-improving-a-model-from-model-perspective" src="https://github.com/user-attachments/assets/d0170ccd-24cc-4e02-9496-f5edbbcf5e69" />

## Next steps

There's some extra-cirricular work after completing workbook 01, where I'm tasked to create another ML model/neural network with a new problem that I'll have the model familiarize itself with and then predict. So pretty much utilizing what I've familiarized myself with these past 2 weeks.

## Reflection

Again, I do want to try put more hours into these workbooks, and boost through each book per week. Though I understand my extra cirriculars with drawing, animating, and gym do get in the way haha, in addition to visiting family overseas.
