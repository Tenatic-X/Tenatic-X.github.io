---
layout: post
title: "Week 25&26"
description: "Week 25&26"
tags: Weekly(ish)_update
todolist: Title, Overview, Projects and Tasks, Challenges and Solutions, Learnings and Insights, Next Steps, Reflections
---

# Week 25&26

## Relevant work
[07 Milestone Project 1: ðŸ”ðŸ‘ Food Vision Big (homework)](https://tenatic-x.github.io/projects/(homework)%2007_milestone_project_1_food_vision_big.html)

[07 Milestone Project 1: ðŸ”ðŸ‘ Food Vision Big (study](https://tenatic-x.github.io/projects/(study)%2007_milestone_project_1_food_vision_big.html)


## Overview
Completed 07 mileston project, and the homework side

## Project and Tasks
* Continuing on 08 workbook on text based ML.

## Challenges and Learnings

### convoluted use of tfds.load - on top of 07 workbook

One thing different with loading in data, is instead of downloading as a zipped file then unzipping it, 07 instead used `tfds.load`, which is absolutely horrible use case wise. Simple extraction leaves the data at 4GB of use space. `tfds.load`, downloading the same data, used 14 damn GB, with zipped files and random copies strewn all over. Not only that, but it took much longer just to download and get it ready. Bloatfile EVERYWHERE. Worst of all, the code I was familiar when extracted, has a different counterpart specifically for `tfds.load`, which made it ever more frustrating.

> **So da fuck is tfds.load's use case?**
> 
> Well based on what chatgpt states, it's based on repeatability and reproducibility in the scientific/research sense. With all data and details, all presented and given in the exact format as to not cause independent variables that were not factored in.

But in the professional/occupational sense, this really isn't useful to us, as data is always going to be unique and not some stored readily available open source information for everyone to see.

### shuffle_files=True (shuffling tfrecords), and parallel preprocessing causing difficulties with shuffling test data

From analyzing data, I wanted to visualize the most confident predictions made by the model, but has it's prediction wrong (exactly the same done in 06) - problem is, because of google colab use and the way it was run, there was no way to achieve this visualization. In addition, I also didn't download the probability values as well, so we wouldn't have known which was the most confident predictions anyways.

> **Shuffle_files=True** - What it does, is tfds has batches of files prestored in the computer (say containing 1-999 images, then 1000-1999 images), and shuffles them across training and test data. So you'd have something like 2000-2999, then 0-999 images. Not a true shuffle, but in the end it does affect the ordering of the images.
>
>  **Parallel preprocessing** - To speed up training process, this allows the computer to finish reading a batch of data, and train it, whilst reading the next batch of data. Rather than completing a full read/train batch cycle, then starting another one. This speeds up training, but comes at the cost of some batches finish training earlier than others, leading to ordering in the prediction results being completely shuffled than what was presented in the start.

### Chatgpt is a hallucinating retard, and I should've spent time testing and playing the code it gave

My own laziness and stuborness was a big downfall for this issue - I wanted to get the code side of things finished ASAP so I can do the analysis on data results, but the one thing that Chatgpt kept getting wrong is 'displaying the 10 worst class in the confusion matrix'. It kept displaying the last 10 class in alphabetical order and say the code has been 'fixed'.

Spent a good hour before finally play testing the code back to a singular line, which is where I found the issue. Took a night's sleep to figure out the best solution to my problem:

```python
    index = f1_scores.index.tolist() # get index variables from our f1-score list, that's already organized in descending order
    worst_indices = index[-10:] # get the last 10 results
```

I should probably be more careful next time, and read the code rather than be so trusting of AI.

### My findings on food 101 class' wrong predictions and confusions

This will be a visual dump with quick summaries of the most important findings - more details can be read on `07 homework` which is linked above on the relevant work section.

<img width="600" height="2010" alt="89018d50-c0fa-4bcf-b2b8-b92115b8d21b" src="https://github.com/user-attachments/assets/7d5ab56f-d42f-4775-80c3-d1ef58a304dd" />

<img width="1989" height="507" alt="e5ed7803-a8dc-4def-844c-53ea4c36edf2" src="https://github.com/user-attachments/assets/e019dcdb-132e-45e1-ba29-238ab1d9cb1c" />

Created a confusion matrix of only the `10 worst class in f1-score`. There's a clear pattern in confusion of certain foods.

<img width="1189" height="439" alt="74ef4833-a8d9-4682-a2be-19a5d966985c" src="https://github.com/user-attachments/assets/5cb96f14-fb35-40c6-95f3-62b234bbe496" />

`Steak` and `Filet mignon` get both confused very often.

<img width="1990" height="989" alt="5d95e132-6126-47c2-92f7-f6d0c186e150" src="https://github.com/user-attachments/assets/2783ad5e-3d9c-41bd-8290-b10fbcf40051" />

`Bread_pudding` to `Apple_pie`, `Chocolate_mousse` to `Chcolate_cake`, and `Beef_tatare` to `Tuna_tatare` are also confused. You can tell based on their similarities.

### Tokenization and Embedding in Language ML

There are two ways discussed that machines can learn language text:

> Tokenization - where each word, sub words, or a character is attached by a single value. This can get very large and difficult to handle with datasets that use a lot of variation of text.
>
> Embedding - where each word is given a vector of any dimension specified, where the numbers relate to how similar or different the word is from another word. For example:
>
```python
dance	[-0.85, 0.45, -0.33, 0.98, 0.11]
sing	[-0.80, 0.50, -0.30, 0.95, 0.12]
cat	[0.10, -0.40, 0.90, 0.20, -0.50]
```
> you can see how `dance` and `sing` are similar, but `cat` is different from the other two. You can state as many dimensions as needed in the vector, as more is useful in large broad language database for contextual understanding of said language.

## Next steps
Continue to finish up the workbook 08.

## Reflection
I found a workaround to taking drugs - it's writing small tasks down on a paper notebook, and giving myself a star per every mini task I complete. It's fun! :)

Also I should be much more involved in reading and testing code that ChatGPT just shits out. Would not want that experience with the `10 worst predictions confusion matrix` shit again.
