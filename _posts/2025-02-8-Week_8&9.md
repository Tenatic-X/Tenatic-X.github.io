---
layout: post
title: "Week 8&9"
description: "Week 8&9"
tags: Weekly(ish)_update
todolist: Title, Overview, Projects and Tasks, Challenges and Solutions, Learnings and Insights, Next Steps, Reflections
---

# Week 8 & 9

## Relevant Project
[02_neural_network_classification_with_tensorflow](https://github.com/Tenatic-X/Tenatic-X.github.io/blob/master/_projects/02_neural_network_classification_with_tensorflow.html)

## Overview
I finished up workbook 02 of TensorFlow ZtM, learning about binary and multi-classification problems, and how to create models that can suit those types of problems.

## Project and Tasks
* Complete 02 workbook: *We just learn the materials set out in 02, mostly on binary and multi classification, but also how we can find the best learning rate*

## Challenges and Learnings

### Sigmoid pattern
This is something I've already discovered from 01's extra-cirricular workbook. When you apply model layers to the neural network, a lot of the times it only shows a straight line through the graph because i didn't include a very essential part to the model. A layer that allows the model to uses non straight lines to predict pattern. This was important for our binary classification, as we're predicting whether a dot belongs to `Oval A`, or `Oval B`.
![21c4d68c-8fa2-4b8b-8c07-d02bb1ba3026](https://github.com/user-attachments/assets/cb9a1494-aebb-4e38-8fa3-f558d2839f78)
This is the binary classification model, and the prediction its trying to make using sigmoid.

![271a687d-8d70-433e-9e58-479b4b30df8c](https://github.com/user-attachments/assets/95a235ff-6e15-4871-ae8f-116f1766b890)
This is without sigmoid.

### Finding the best learning rate of model
One new concept, is trying to find what the best learning rate of the model is. The thing is, we'll need to increase the learning rate exponentialy, as we usually update from `0.0001`, to `0.001`, then `0.01` etc. This is donw using `LearningRateScheduler()`, allowing us to do changes on the learning rate as the model progresses from epoch to epoch. In this rule, we use `1e-4 * 10 ** (epoch/20)`, where we have an exponent rule to increase by epoch no./20.

**I noticed how learning rate consistent and effective at exponents of 10**: What I mean is anything like `0.001` or `0.1`. Despite seeing a trough that aligns on a non-1 value of the learning rate such as `0.4` ot `0.025`, I implement it onto my actual model, and sometimes it works, but sometimes it doesn't. I get more consistent results with exponents of `1` for some reason.

**Explanation on learning rates being only on power of 10s**: I decided to look into this by asking deepseek, and a main proposition to this, is due to research efficiency. Learning rates increase exponentially, not linearly, so it's more efficient to find the right learning rate, through powers of 10, rather than a slow incremental process of 0.1, 0.2, 0.3... It also seems to work well for machine models at times, based on other's past experience, in addition to its simplicity just by reading the code. It did suggest that such specific learning rates can be used, once initial experiments are done, and the goal is to get the model more accurate. 

### Confusion matrix
This is something I've learnt a bit from the Microsoft Accelerator uni program from last year, but it's good to revisit something that I'm rusty again on. The concept of it is easy for me to understand, but the code is definitely quite the headache.

```python
# Note: The following confusion matrix code is a remix of Scikit-Learn's 'plot_confusion_matrix', and made with ML's introductory notebook https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb
import itertools

figsize = (10,10)

# create the confusion matrix
cm = confusion_matrix(y_test, tf.round(y_preds))
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # normalizing, 'float' > we'll be dividing, 'cm.sum' to count all values of truth labels and dividing it everytime with each prediction, false or negative
                                                             # aka, this is a percentage calculator, calculating how many percent of the prediction was in 1, in 0, or at another 3rd label.
n_classes = cm.shape[0] # extract true values from column 0

# Let's prettify it
fig, ax = plt.subplots(figsize=figsize)
# create a matrix plot
cax = ax.matshow(cm, cmap=plt.cm.Blues) # https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.axes.Axes.matshow.html
                                        # matshow > heatmap for our confusion matrix, cmap > to colour our graph with blue to visually represent values on heatmap
                                        # saving it as variable for later modification
fig.colorbar(cax) # add colourbar to reference against the values

# create classes to identify between true values and prediction
classes = False

if classes:
    labels = classes
else:
    labels = np.arange(cm.shape[0])

# label the axes
ax.set(title='Confusion Matrix',
       xlabel='Predicted label',
       ylabel='True label',
       xticks=np.arange(n_classes), # specifying placement of ticks. Ticks are like placeholder of major points/value to the graph, aka the labels that goes on the graph.
       yticks=np.arange(n_classes),
       xticklabels=labels,
       yticklabels=labels)

# Set x-axis labels to bottom
ax.xaxis.set_label_position('bottom')
ax.xaxis.tick_bottom()

# Adjust label size
ax.xaxis.label.set_size(20)
ax.yaxis.label.set_size(20)
ax.title.set_size(20)

# set threshold for diferent colours
threshold = (cm.max() + cm.min()) / 2. # find the midpoint value between min and max. Helps with colouring text annotations, when choosing black, or white, based on the supposed contrast of the colour at the back.

# plot the text on each cell, looping until all text is added
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): # i and j, representing true and predicted values respectively
    plt.text(j, i, f'{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)', # format them into percentage of output. Aka out of all 1s that are true, how many are predicted as 1, or 0 as a percentage?
             horizontalalignment='center', # centers text inside the cell
             color='white' if cm[i, j] > threshold else 'black', # text colour based on the contrast of the cell at the back. Done by seeing whether its at the upper half or lower half of values.
             size=15)
```
Quite the lot to look, and I made sure to comment stuff that I was unfamiliar on so I could come back to this when I forget the minute I finish reading this shit lol.
![e4ccaf3d-598b-4ce8-9cb2-b4849456e091](https://github.com/user-attachments/assets/60092fad-9df7-4563-929a-3121bd989865)
Results is definitely cool!

### Inner workings of the ML model
A cool thing to see, is that you can get the weights and the biases the model has, after training it has been trained on a particular dataset. Obviously its just numbers with very little human legibility of how the model does it's job, but still intersting nevertheless.

## Next steps

Continue on the homework section of 02 workbook. Will see if I could start back on my weight and waist ML prediction model as well, since I'm back in town.

## Reflection

It's been pretty slow, getting busy with flying back home and settling back home with jet lag, and also doing an art commission. Fun fact, my last commission was 4 years ago lol.
