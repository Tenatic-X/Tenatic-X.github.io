---
layout: post
title: "Week 22&23"
description: "Week 22&23"
tags: Weekly(ish)_update
todolist: Title, Overview, Projects and Tasks, Challenges and Solutions, Learnings and Insights, Next Steps, Reflections
---

# Week 22 & 23

## Overview
Continuing on tensorflow course work 05, and finishing up workbook 04 homework.

## Project and Tasks
* Reading Ulmfit text classification
* Continuing 06 - scaling up part 3

## Challenges and Learnings

### Sciency jargon from Ulmfit science paper
Its hard for me to stay focused on reading a wall of text, and it was another challenge for data sciency heavy lingo lol. Luckily having Chatgpt summarizing every chapter, in addition to me regurgitating what I was reading back to Chatgpt to correct me, helped me understand it in better context.

### How to get a language model good at a task specific problem
Paper describes how difficult it is to get the model to learn the patterns of English, no less on context and prediction of things, whether it be sentiment, or predicted review rating. However there's a 3 step process to breach that gap.

1. Train the model on a huge bank of english data that can be used as a general starting point. E.g. using wikipedia
2. Fine tune the model using data that represents the problem, you are targetting so the model understands the specificity on the type of context, English is playing. E.g. Imdb reviews
3. Fine tune again, but with an extra input layer that starts predicting the problem with a few labeled data to learn from. E.g. learning what makes a 1 star review or 10 star in Imdb

### The ulmfit traingle
Normal finetuning, where unfreezing a number of layers then train again won't suffice. This causes too much forgetting of previous knowledge in English because learning rate is too high overall. To navigate this issue, when starting a `lr` of a layer, we would increase it quickly for a number of iterations, before gradually decreasing `lr` back, to kind of let the model weights settle slowly. This creates a slanted triangle shop for the `lr` overtime, during the iterations/batches the model goes through. 

On the next epoch, the model goes down a layer, but `lr` is reduced by `/2.6`, as deeper the layer you go, the more general knowledge the layer has about english. Meaning higher `lr` to these layers will cause the model to easily forget English. While upper layers have very specific knowledge, and is therefore not heavily afflicted from higher `lr. Again, these layers perform the slanted triangle shape of `lr`, with top layer at `x` of `lr`, and second layer at `x/2.6` of `lr`. And so on.

### Training via fine-tuned model


## Next steps
Continue to finish up the workbook 05 homework.

## Reflection
Not much, except busy with 6 day work weeks. Already at streak number 9, of weeks with working 6 days lol. So not a whole lot of down time to practice and study.
