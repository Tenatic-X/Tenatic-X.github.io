---
layout: post
title: "Week 24"
description: "Week 24"
tags: Weekly(ish)_update
todolist: Title, Overview, Projects and Tasks, Challenges and Solutions, Learnings and Insights, Next Steps, Reflections
---

# Week 24

## Relevant work
[06_exercise_transfer_learning_with_tensorflow_part_3_scaling_up (homework)](https://tenatic-x.github.io/projects/(homework)%2006_exercise_transfer_learning_with_tensorflow_part_3_scaling_up.html)
[06_transfer_learning_with_tensorflow_part_3_scaling_up (study](https://tenatic-x.github.io/projects/(study)%2006_transfer_learning_with_tensorflow_part_3_scaling_up.html)
[HTML workbook setup guide](https://tenatic-x.github.io/projects/WORKBOOK_SETUP.html)


## Overview
Completed 06 homework
Doing tensorflow 07 milestone workbook

## Project and Tasks
* Continuing on 07 workbook milestone
* Html fixer-upper when uploading projects

## Challenges and Learnings

### Food model is extremely sensitive to images - Technically a `Dish` model
On the 06 homework, they wanted me to take pictures of at least 3 food items. Out of curiosity and pure laziness, I picked whatever items around the kitchen that are foods, but aren't really classified as dishes. After showing the 3 pictures to the model, they really struggled and got all predictions wrong. Here are the following images.

<img width="320" height="411" alt="0d167c6c-91bb-47a1-8234-19833eb01649" src="https://github.com/user-attachments/assets/c88379b5-9bda-49d5-ae9a-aefca0f53f28" />
<img width="320" height="411" alt="59c5f1c6-bfeb-40e4-a0ce-c99b59c3901b" src="https://github.com/user-attachments/assets/4e8dc02b-c542-407c-afd1-8241797b8bec" />
<img width="320" height="411" alt="36d60d56-98fa-49c3-907f-f03082beec5f" src="https://github.com/user-attachments/assets/1fb5f4ca-c014-48e3-9692-64339f69c31d" />

The correct food is: `Meat pie`, `Cherry Tomatoes`, `Rice`. I will also accompany the food images that the model 'thinks' the pictures are as well to give a better visual comparison in their prediction order.

<img width="320" height="411" alt="0d167c6c-91bb-47a1-8234-19833eb01649" src="https://github.com/user-attachments/assets/4c62e455-9f9b-4ab3-bb66-676f47168576" />
<img width="320" height="411" alt="36d60d56-98fa-49c3-907f-f03082beec5f" src="https://github.com/user-attachments/assets/22fb4508-23fb-4b16-9714-29b2d4c42d4f" />
<img width="320" height="411" alt="59c5f1c6-bfeb-40e4-a0ce-c99b59c3901b" src="https://github.com/user-attachments/assets/3e2e1a46-fd71-415f-a4e4-aa9460f1fd79" />

We can see theres visual similarity between them (less so with doughnuts and cherry tomatoes), but why is the model so off in it's predictions? The most obvious answer is the model isn't a `Food` model, but more so a `Dish` model. The images I gave are food, but they are more so singular or accompanying ingredients that you combine into a dish. Like rice in sushi, or cherry tomato in a salad. Plus, the display of food from my images are very non conventional presentation of foods.

When taking picture of foods and dishes, you present them in a very appealing and colourful way, usually in a bowl or a plate with certain garnishes to enhance the colour and shape of the food. But mine is literally a large mass of the item, no presentation, no plate, just sitting on the table or inside it's container. You can see the clear difference in presentation between the images I pulled from the web, and the images of my food.

This makes my pictures extremely different from the database, and it might as well be the wrong use case as well. Still gives a very interesting insight to how much I can stress/push the limits of the model.

### Use of `mixed_precision`
There is a form of model training called `mixed_precision`, where instead of using `float32` to train the model, we use a mix of `float16` as well. Using `float16` halves the number of bits to calculate, therefore saving tons of time calculating very specific values.

However, the output layer must stay at `float32` because of how big the values can get. Having `float16` will overflow and return `inf` instead of a proper value.

This can speed up training 2 to 4 times, however its only limited to if you're rich enough to afford the powerful GPUs. If running on lower end GPUs and CPUs alone, it'll take much longer than if done on `float32`, because the computer needs to calculate for the switch from `float32` to `float16` which takes a lot of time (but doesn't take much effort for the good GPUs).

### Html is a picky bitch :( - created quick guide html notebook
So I spent about 2 hours, twiddling the nutsacks of html to finally get my workbook uploaded onto github, and become viewable. However for the longest time, it kept showing a 404 error. The thing that got the projects working again is as simple as: `{% raw %}` Then `{% endraw %}`. You wrap this code around the entire body of the html script that is outputted from VScode.

What this does is it tells the computer to treat all code within the html script as literal information - no fancy bullshit.

The other reason was because of date - Github is most likely anchored it's date time to the USA. Living in NZ, this makes me about a day in front of the USA, making my date time in the future. This messes with Github and also makes it refuse to show me my files, because it only reads files from the present day, and it's past. So I have to make sure to note my notebook date a day before mine to get Github to read it.

In the end, a made an [html quick guide](https://tenatic-x.github.io/projects/WORKBOOK_SETUP.html) for myself whenever I need to upload projects.

### `Mixed_precision` training workaround for 07 workbook
Workbook 07 makes use of `mixed_precision`, which my pc is unable to handle. However the notebook has assumed that we're working with `google colab` to do the training (though I've been using `VScode`). To alleviate this, I'm copying any nessecary code from `VScode`, and running it on `google colab`, then copying the output training results vack into `VScode`, and also export the model or other files if need be.

## Next steps
Continue to finish up the workbook 07.

## Reflection
It's nice to be on adhd pills (rubifen). Now I feel like I can get stuff done lol.
